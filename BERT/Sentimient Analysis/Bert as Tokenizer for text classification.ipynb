{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert as Tokenizer for text classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMVb5niZHke8zCFmwcGcOMU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"E7H3bhopeXok","colab_type":"text"},"source":["## Classifying the text using BERT\n","### By using BERT as tokenizer we will pull out vocabulary file and as use it as tokenizer to convert sentence to tokens and tokens to id's\n","\n","#### Dataset used: Standford tweets\n","#### We will use data from drive and for picking up data from drive we use google.colab library\n","##### Lets get Started!!"]},{"cell_type":"markdown","metadata":{"id":"tqsQV_8iewE6","colab_type":"text"},"source":["## Import Dependencies\n","### Beautifulsoup is to convert xml format to string"]},{"cell_type":"code","metadata":{"id":"8kN0xK-0eR8p","colab_type":"code","colab":{}},"source":["import numpy as np\n","import re\n","import tensorflow as tf\n","from tensorflow import keras\n","import math\n","import pandas as pd\n","import random #For shuffling the dataset\n","from bs4 import  BeautifulSoup #The input data would be in XML form"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"702Jrhxdf5FZ","colab_type":"text"},"source":["Performing Bert becomes easy by 'bert-for-tf2' library\n","sentencepiece is prerequisite fot bert-for-tf2\n"]},{"cell_type":"code","metadata":{"id":"lTf68U9SfW7q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"status":"ok","timestamp":1597582615535,"user_tz":-330,"elapsed":19114,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"f1875e7d-9fc8-4a4f-e1fd-64322671f41f"},"source":["!pip install bert-for-tf2\n","!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/df/ab6d927d6162657f30eb0ae3c534c723c28c191a9caf6ee68ec935df3d0b/bert-for-tf2-0.14.5.tar.gz (40kB)\n","\r\u001b[K     |████████                        | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 1.8MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.5-cp36-none-any.whl size=30315 sha256=a5e2bc2ea68dacabc6bab3006845a588274435d953b7de6555a6e3b25d4a3084\n","  Stored in directory: /root/.cache/pip/wheels/2e/70/a2/be357037dd2cbdcaeb0add1fdf083be6a600ca65ee1f68751c\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=a03e6363a42088a64c58cf6c5d88d9fb0d0eba042e357ae56f0bb55fc3137958\n","  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=279d9b62f6e9b094d1c47c17d1b0a672aba6e0e0bc2d4b4d80e2b123b2da5540\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.5 params-flow-0.8.2 py-params-0.9.7\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 2.7MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.91\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"va8qaL3fgszq","colab_type":"text"},"source":["All the  variables of Bert can be retrieved from Tensorflow_hub.\n","Tensorflow hub is a place where we get all the pretrained models of Text, image as well as video.\n","This is basically a Transfer learning\n"]},{"cell_type":"code","metadata":{"id":"jK4QIM3dgKkm","colab_type":"code","colab":{}},"source":["#Bert is bert-for-tf2 library which soimply called as bert\n","import bert\n","import tensorflow_hub as hub"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ucrC4kythGql","colab_type":"text"},"source":["## Data import\n","#### Data is being imported from Google drive.\n","#### For this mounting of google drive is required, which colab has a method to mount"]},{"cell_type":"code","metadata":{"id":"bKEOlB1GgzMz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1597585276864,"user_tz":-330,"elapsed":1062,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"7bebc669-478e-48d9-cafd-d93d541d2de8"},"source":["from google.colab import drive\n","##Mount the drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sfC555LJiTX1","colab_type":"text"},"source":["Data: It does not include columns and custom columns are created for representation.\n","encoding='latin1' as Data is present in latin1 encoding \n","We will give encoding as latin1 because most of the english code is latin encoded\n","\n"]},{"cell_type":"code","metadata":{"id":"fwHXibaAh5Vf","colab_type":"code","colab":{}},"source":["column_names=[\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n","data= pd.read_csv('/content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/train.csv',\n","                  header=None,\n","                  names=column_names,\n","                  engine='python',encoding='latin1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i85O5bxYjoMd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":288},"executionInfo":{"status":"ok","timestamp":1597547151800,"user_tz":-330,"elapsed":362539,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"8a3f65f9-6c92-4197-8a3b-8dcdfe03bcff"},"source":["##Sample Data\n","data.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>query</th>\n","      <th>user</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1467810369</td>\n","      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>_TheSpecialOne_</td>\n","      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1467810672</td>\n","      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>scotthamilton</td>\n","      <td>is upset that he can't update his Facebook by ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1467810917</td>\n","      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>mattycus</td>\n","      <td>@Kenichan I dived many times for the ball. Man...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1467811184</td>\n","      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>ElleCTF</td>\n","      <td>my whole body feels itchy and like its on fire</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1467811193</td>\n","      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>Karoli</td>\n","      <td>@nationwideclass no, it's not behaving at all....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment  ...                                               text\n","0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n","1          0  ...  is upset that he can't update his Facebook by ...\n","2          0  ...  @Kenichan I dived many times for the ball. Man...\n","3          0  ...    my whole body feels itchy and like its on fire \n","4          0  ...  @nationwideclass no, it's not behaving at all....\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"1mu5-HoCjqq1","colab_type":"code","colab":{}},"source":["## Dropping below columns as they dont serve any purpose \n","data.drop([ \"id\", \"date\", \"query\", \"user\"],axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"plo6S1QMj_6W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1597547151807,"user_tz":-330,"elapsed":362464,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"16f306b4-cfd1-4a7e-b2e0-fdacaec293c3"},"source":["data.tail(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1599995</th>\n","      <td>4</td>\n","      <td>Just woke up. Having no school is the best fee...</td>\n","    </tr>\n","    <tr>\n","      <th>1599996</th>\n","      <td>4</td>\n","      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n","    </tr>\n","    <tr>\n","      <th>1599997</th>\n","      <td>4</td>\n","      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n","    </tr>\n","    <tr>\n","      <th>1599998</th>\n","      <td>4</td>\n","      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n","    </tr>\n","    <tr>\n","      <th>1599999</th>\n","      <td>4</td>\n","      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         sentiment                                               text\n","1599995          4  Just woke up. Having no school is the best fee...\n","1599996          4  TheWDB.com - Very cool to hear old Walt interv...\n","1599997          4  Are you ready for your MoJo Makeover? Ask me f...\n","1599998          4  Happy 38th Birthday to my boo of alll time!!! ...\n","1599999          4  happy #charitytuesday @theNSPCC @SparksCharity..."]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"XCwWm12VXekp","colab_type":"text"},"source":["Label Values has 0 and 4 for positive and negative respectively.\n","Coverting  values from 0, 4 to 0, 1 will become easy for binary classificaton."]},{"cell_type":"code","metadata":{"id":"XbOSO04wkQTv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1597547151809,"user_tz":-330,"elapsed":362401,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"6e0fe162-2cbe-4f36-fd1a-76b7169872c5"},"source":["\n","data.sentiment.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    800000\n","0    800000\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Igh4avcmnMz3","colab_type":"code","colab":{}},"source":["\n","data.sentiment= data.sentiment.apply(lambda label: 1 if label==4 else label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EkpcyNtkIyb","colab_type":"text"},"source":["## Data Preprocessing\n","#### Data preprocessing contains cleaning of text such as converting text from lxml to text, removing @tags, urls, removing un-necessary symbols etc., "]},{"cell_type":"code","metadata":{"id":"XA6AmJB2kENC","colab_type":"code","colab":{}},"source":["## We will clean the data by using function\n","def clean_data(text):\n","  ##Conver the text from lxml from text\n","  text= BeautifulSoup(text,'lxml').get_text()\n","  ##Remove @tags from the text\n","  text= re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n","\n","  ##Remove links\n","  text= re.sub(r\"https?://[A-Za-z0-9./]+\",' ', text)\n","  ##Keeping only letters in the tweets\n","  text= re.sub(r\"[^A-Za-z0-9.?!]+\",' ', text)\n","\n","  ##removing the whitespaces\n","  text= re.sub(r\" +\",' ', text)\n","\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3JsvQgQmT5q","colab_type":"code","colab":{}},"source":["## Now lets call the function to the text\n","data.text= data.text.apply(lambda text:clean_data(text))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1j1uyh--Oz7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"ok","timestamp":1597547436911,"user_tz":-330,"elapsed":647308,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"a333cb94-9ef6-4f8e-a037-8d0c284e7599"},"source":["data.tail(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1599990</th>\n","      <td>1</td>\n","      <td>WOOOOO! Xbox is back</td>\n","    </tr>\n","    <tr>\n","      <th>1599991</th>\n","      <td>1</td>\n","      <td>Mmmm That sounds absolutely perfect... but my...</td>\n","    </tr>\n","    <tr>\n","      <th>1599992</th>\n","      <td>1</td>\n","      <td>ReCoVeRiNg FrOm ThE lOnG wEeKeNd</td>\n","    </tr>\n","    <tr>\n","      <th>1599993</th>\n","      <td>1</td>\n","      <td>GRITBOYS</td>\n","    </tr>\n","    <tr>\n","      <th>1599994</th>\n","      <td>1</td>\n","      <td>Forster Yeah that does work better than just ...</td>\n","    </tr>\n","    <tr>\n","      <th>1599995</th>\n","      <td>1</td>\n","      <td>Just woke up. Having no school is the best fee...</td>\n","    </tr>\n","    <tr>\n","      <th>1599996</th>\n","      <td>1</td>\n","      <td>TheWDB.com Very cool to hear old Walt intervie...</td>\n","    </tr>\n","    <tr>\n","      <th>1599997</th>\n","      <td>1</td>\n","      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n","    </tr>\n","    <tr>\n","      <th>1599998</th>\n","      <td>1</td>\n","      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n","    </tr>\n","    <tr>\n","      <th>1599999</th>\n","      <td>1</td>\n","      <td>happy charitytuesday</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         sentiment                                               text\n","1599990          1                              WOOOOO! Xbox is back \n","1599991          1   Mmmm That sounds absolutely perfect... but my...\n","1599992          1                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd \n","1599993          1                                          GRITBOYS \n","1599994          1   Forster Yeah that does work better than just ...\n","1599995          1  Just woke up. Having no school is the best fee...\n","1599996          1  TheWDB.com Very cool to hear old Walt intervie...\n","1599997          1  Are you ready for your MoJo Makeover? Ask me f...\n","1599998          1  Happy 38th Birthday to my boo of alll time!!! ...\n","1599999          1                              happy charitytuesday "]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"8wkthIWB-Osz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kcZhtfHx9xR7","colab_type":"text"},"source":["## Tokenization\n","Creation of Tokens and converting sentence to tokens followed by id's is done by Bert layer.\n","Bert layer is captured from tensorflow hub directory and vocabfiles and other parameters are drawn.\n","By using bert-for-tf2 we will create tokenizer and process the tokenization."]},{"cell_type":"code","metadata":{"id":"AboWNd359vnK","colab_type":"code","colab":{}},"source":["### Instantiate full tokenizer from bert library\n","fulltokenizer= bert.bert_tokenization.FullTokenizer\n","##instantiate Bert layer\n","bert_layer= hub.KerasLayer(handle= \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n","                           trainable=False)\n","##Create vocab file\n","vocab_file= bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","##Create lowercase parameter\n","lower_case= bert_layer.resolved_object.do_lower_case.numpy()\n","##Pass vocab_file and lower_case parameters to bert library\n","token= fulltokenizer(vocab_file, lower_case)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hF72K5RnBS5l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597547452973,"user_tz":-330,"elapsed":663251,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"87b68955-f94f-474d-8f39-b0e27a388195"},"source":["type(lower_case),lower_case"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(numpy.bool_, True)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"KCj6Cgk1BYud","colab_type":"code","colab":{}},"source":["## Now lets encode the sentence by convert the sentence to tokens and later tokens to Id's\n","def encode_tokens(sent):\n","  ##Convert sentence to tokens (tokens are not numbers or id's it will divide the sentence into words)\n","  sent_token= token.tokenize(sent)\n","  #print(sent_token)\n","  ###Converting words to ids\n","  token_id= token.convert_tokens_to_ids(sent_token)\n","  return token_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zGwmCcIB_Yy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597557251370,"user_tz":-330,"elapsed":1012,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"261c112d-f840-4480-f2e2-778669fd2ef4"},"source":["encode_tokens(u\"I am colo\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1045, 2572, 8902, 2080]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"8YMdq1cICCvv","colab_type":"code","colab":{}},"source":["data_inputs= data.text.apply(lambda text: encode_tokens(text))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhPK8HmZZmgy","colab_type":"text"},"source":["Conversion of dataseries to list"]},{"cell_type":"code","metadata":{"id":"1CWSjALaDWS7","colab_type":"code","colab":{}},"source":["data_text= data_inputs.tolist()\n","data_label= data.sentiment.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O1G4ozDZGQP8","colab_type":"text"},"source":["## Dataset Creation\n","Dataset is creted from the above generated lists.\n","Below are the steps followed to create dataset\n","1. Create list combination of sentence, label and length of sentence\n","2. Sorting of the result list with length of sentence and we will remove rows which the minimum length of 7 and below.\n","  2.1 This is because, while creating model we are using n-gram(bi, tri and four). If we won't remove length which is less than 7 , we cannot use four gram. whcih would reduce some accuracy.\n","  2.2. As because we are sorting the lengths we would get lengthof sentence in order.\n","\n","3. dataset is created using generator.\n","4. Padded batches are also created. where we dnt have to bother about pad_sequencing the token ids"]},{"cell_type":"code","metadata":{"id":"UZoWhKqjGI-Q","colab_type":"code","colab":{}},"source":["data_with_len=[[sent, data_label[i], len(sent)] for i, sent in enumerate(data_text)]\n","## WE will shuffle the dataset\n","random.shuffle(data_with_len)\n","##We will sort with the length\n","data_with_len.sort(key=lambda x: x[2])\n","##Lets take only those with len > 7\n","sorted_all= [(sent[0], sent[1]) for sent in data_with_len if sent[2] >7]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbckqtSMaBQy","colab_type":"code","colab":{}},"source":["##Lets create a dataset as it is a list we will cretae data from-generator\n","dataset= tf.data.Dataset.from_generator(lambda: sorted_all, output_types=(tf.int32, tf.int32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"daiv1bXAas08","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1597547735463,"user_tz":-330,"elapsed":945422,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"b28945d8-d2fc-4004-bf29-ba70a05cb614"},"source":["next(iter(dataset))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(8,), dtype=int32, numpy=\n"," array([ 1045,  2074,  2179,  2041, 16371, 13871,  8454,  2439],\n","       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"nCNL2yp7aTed","colab_type":"code","colab":{}},"source":["batch_size=32\n","dataset= dataset.padded_batch(batch_size=batch_size, padded_shapes=((None,), ()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfWIvI-GbDDZ","colab_type":"text"},"source":["## Model Building\n","Before creating model, shuffling of dataset happens, if the dataset is splitting to train and test.\n","\n","### Model Layers:\n","Below are the list of layers used in the model:\n","##### Embedding\n","##### Bigram\n","##### Trigram\n","##### fourgram\n","##### Concatination of n-grams\n","##### Dense\n","##### Dropout layer\n","##### Output layer"]},{"cell_type":"code","metadata":{"id":"zrby2e56a0Cn","colab_type":"code","colab":{}},"source":["num_batches= math.ceil(len(sorted_all) / batch_size)\n","num_batches_test= num_batches//10\n","dataset.shuffle(num_batches)\n","test_dataset= dataset.take(num_batches_test)\n","train_dataset= dataset.skip(num_batches_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNKflH_OcaMN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597555834726,"user_tz":-330,"elapsed":907,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"3405c185-3e68-4723-a99b-b2a5de97d3e8"},"source":["num_batches_test, num_batches"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4118, 41188)"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"o7UjkQ8xvoTD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597555845839,"user_tz":-330,"elapsed":1073,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"092e346f-f36b-42c9-821c-c02e052d0fbd"},"source":["len(sorted_all)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1318004"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"pMVcl2zrcpC0","colab_type":"text"},"source":["Model Building"]},{"cell_type":"code","metadata":{"id":"b3-TEaKqMgGc","colab_type":"code","colab":{}},"source":["class DNN(tf.keras.Model):\n","\n","  def __init__(self, vocab_size, embed_dim=128, num_filters=50,\n","              num_units=512, num_classes=2, dropout_rate=0.1,\n","              trainable=False, name='dcnn'):\n","    super(DNN, self).__init__(name= name)\n","    \n","\n","\n","    ##Embed layer\n","    self.embed= keras.layers.Embedding(input_dim= vocab_size, output_dim= embed_dim)\n","\n","    #Bigram layer\n","    self.bigram= keras.layers.Conv1D(filters= num_filters, kernel_size=2, activation=tf.nn.relu,  padding='VALID')\n","\n","    ##Tri gram\n","    self.trigram= keras.layers.Conv1D(filters= num_filters, kernel_size=3, activation=tf.nn.relu, padding='VALID')\n","\n","    ##fourgram\n","    self.fourgram= keras.layers.Conv1D(filters= num_filters, kernel_size=4, activation=tf.nn.relu, padding='VALID')\n","\n","    ## GlobaLAveragePool\n","    self.globalpooling= keras.layers.GlobalMaxPool1D()\n","\n","    ##Dense\n","    self.dense= keras.layers.Dense(units= num_units, activation=tf.nn.relu)\n","\n","    ##Dropout\n","    self.dropout= keras.layers.Dropout(rate= dropout_rate)\n","\n","\n","    self.output_layer= keras.layers.Dense(units= 1, activation='sigmoid')\n","\n","  \n","  def call(self, inputs, training):\n","    x= self.embed(inputs)\n","\n","    x_1= self.bigram(x)# batch_size, nb_filters, seq_len-1)\n","    x_1= self.globalpooling(x_1)# (batch_size, nb_filters)\n","    x_2= self.trigram(x)# batch_size, nb_filters, seq_len-1)\n","    x_2= self.globalpooling(x_2)# (batch_size, nb_filters)\n","    x_3= self.fourgram(x)# batch_size, nb_filters, seq_len-1)\n","    x_3= self.globalpooling(x_3)# (batch_size, nb_filters)\n","\n","    ##Concat the ngram layers to the last dimension\n","    concat= tf.concat([x_1, x_2, x_3], axis=-1)# (batch_size, 3* nb_filters)\n","    x= self.dense(concat)\n","    x= self.dropout(x, training)\n","\n","    output= self.output_layer(x)\n","\n","    return output\n","     \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66ev4d3uiG9F","colab_type":"text"},"source":["## Model Training\n","### We will compile the model and train it with 5 epochs"]},{"cell_type":"code","metadata":{"id":"8ZVzDOPaiD2j","colab_type":"code","colab":{}},"source":["\n","vocab_size= len(token.vocab)\n","embed_dim= 200\n","num_filters= 100\n","num_classes= 2\n","num_units= 256\n","dropout_rate= 0.2\n","num_epochs= 5\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYJwlKEgAN50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597562779711,"user_tz":-330,"elapsed":1068,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"9b8e7ddd-e626-48ea-e1ae-b165da419032"},"source":["print(vocab_size, embed_dim, num_filters, num_units, num_classes, dropout_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30522 200 100 256 1 0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rnW5iPt6CMw5","colab_type":"code","colab":{}},"source":["\n","Dcnn= DNN(vocab_size, embed_dim, num_filters, num_units, num_classes, dropout_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVArConxiwWC","colab_type":"code","colab":{}},"source":["## Now lets compile the model\n","Dcnn.compile(optimizer= 'adam', loss= 'binary_crossentropy',\n","             metrics=['accuracy'])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cieIB3B5kYS_","colab_type":"text"},"source":["### Checkpoint Manager\n","Setting up the checkpoint path\n","Creating checkpoint with class name(which is model name)\n","Creating checkpoint manager and passing checkpoint path aswellas checkpoint method\n"]},{"cell_type":"code","metadata":{"id":"cl8T8a6JjjR0","colab_type":"code","colab":{}},"source":["checkpoint_path='/content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/ckpt_bert_tok'\n","checkpoint= tf.train.Checkpoint(Dcnn= Dcnn)\n","##Maxto_keep will keep the latest n number of checkpoint files\n","checkpoint_man= tf.train.CheckpointManager(checkpoint, \n","                                           checkpoint_path, max_to_keep=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OuKWrmLynbQW","colab_type":"text"},"source":["Callback function is created so that checkpoint would be saved after every epoch"]},{"cell_type":"code","metadata":{"id":"AKT-WAUEkUYa","colab_type":"code","colab":{}},"source":["class MyCallBack(tf.keras.callbacks.Callback):\n","\n","  def on_epoch_end(self, epoch, logs=None):\n","    checkpoint_man.save()\n","    print(\"Checkpoint saved at {}\".format(checkpoint_path))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFlHGwQqn3I8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"ok","timestamp":1597575689521,"user_tz":-330,"elapsed":10496249,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"53e6472c-e4c9-4ea5-8bec-9a6f2de71817"},"source":["##Lets train the model\n","Dcnn.fit(train_dataset, epochs= num_epochs, callbacks=[MyCallBack()])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","  37070/Unknown - 2102s 57ms/step - loss: 0.4294 - accuracy: 0.8021Checkpoint saved at /content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/ckpt_bert_tok.\n","37070/37070 [==============================] - 2102s 57ms/step - loss: 0.4294 - accuracy: 0.8021\n","Epoch 2/5\n","37069/37070 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8309Checkpoint saved at /content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/ckpt_bert_tok.\n","37070/37070 [==============================] - 2081s 56ms/step - loss: 0.3809 - accuracy: 0.8309\n","Epoch 3/5\n","37070/37070 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8524Checkpoint saved at /content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/ckpt_bert_tok.\n","37070/37070 [==============================] - 2071s 56ms/step - loss: 0.3399 - accuracy: 0.8524\n","Epoch 4/5\n","37070/37070 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8729Checkpoint saved at /content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/ckpt_bert_tok.\n","37070/37070 [==============================] - 2114s 57ms/step - loss: 0.2981 - accuracy: 0.8729\n","Epoch 5/5\n","37070/37070 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.8904Checkpoint saved at /content/drive/My Drive/NLP/Projects/BERT/Sentimental Data/ckpt_bert_tok.\n","37070/37070 [==============================] - 2064s 56ms/step - loss: 0.2594 - accuracy: 0.8904\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff95ee1ecc0>"]},"metadata":{"tags":[]},"execution_count":147}]},{"cell_type":"code","metadata":{"id":"bHWSe8ZToDKA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"status":"ok","timestamp":1597576310150,"user_tz":-330,"elapsed":973,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"72f6f055-db55-4634-9474-0ea5b48cec52"},"source":["Dcnn.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"dcnn\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_20 (Embedding)     multiple                  6104400   \n","_________________________________________________________________\n","conv1d_60 (Conv1D)           multiple                  40100     \n","_________________________________________________________________\n","conv1d_61 (Conv1D)           multiple                  60100     \n","_________________________________________________________________\n","conv1d_62 (Conv1D)           multiple                  80100     \n","_________________________________________________________________\n","global_max_pooling1d_19 (Glo multiple                  0         \n","_________________________________________________________________\n","dense_40 (Dense)             multiple                  77056     \n","_________________________________________________________________\n","dropout_20 (Dropout)         multiple                  0         \n","_________________________________________________________________\n","dense_41 (Dense)             multiple                  257       \n","=================================================================\n","Total params: 6,362,013\n","Trainable params: 6,362,013\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BKch7yRraTuJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1597576350009,"user_tz":-330,"elapsed":23374,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"outputId":"f51afe90-ebcf-4c8a-b264-d5c020db044c"},"source":["Dcnn.evaluate(test_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4118/4118 [==============================] - 23s 5ms/step - loss: 0.4275 - accuracy: 0.8303\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.4274745285511017, 0.8303029537200928]"]},"metadata":{"tags":[]},"execution_count":149}]},{"cell_type":"markdown","metadata":{"id":"mG44JWKCeLBB","colab_type":"text"},"source":["## Prediction\n","Prediction is done by taking the sentence and cleaning as done for training data, then converting to tokens followed by id's"]},{"cell_type":"code","metadata":{"id":"ZaU2YxqflFzv","colab_type":"code","colab":{}},"source":["def get_prediction(sentence):\n","    tokens = encode_tokens(sentence)\n","    inputs = tf.expand_dims(tokens, 0)\n","\n","    output = Dcnn(inputs, training=False)\n","\n","    sentiment = math.floor(output*2)\n","\n","    if sentiment == 0:\n","        print(\"Ouput of the model: {}\\nPredicted sentiment: negative.\".format(\n","            output))\n","    elif sentiment == 1:\n","        print(\"Ouput of the model: {}\\nPredicted sentiment: positive.\".format(\n","            output))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ar2uXkcD-mlw","colab_type":"code","colab":{}},"source":["get_prediction(u\"The movie is pretty good\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0AEPgks-qvf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}